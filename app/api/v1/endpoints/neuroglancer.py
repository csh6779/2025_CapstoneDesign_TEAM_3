# app/api/v1/endpoints/neuroglancer.py
"""
Neuroglancer ê´€ë ¨ API ì—”ë“œí¬ì¸íŠ¸
- ì´ë¯¸ì§€ ì—…ë¡œë“œ ë° ì²­í¬ ë³€í™˜
- ë³¼ë¥¨ ê´€ë¦¬
- ë©”ëª¨ë¦¬ ìƒíƒœ ì¡°íšŒ
- ëŒ€ìš©ëŸ‰ TIFF íŒŒì¼ì„ ìœ„í•œ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
"""

import os
import shutil
import json
from pathlib import Path
from typing import List, Optional
from fastapi import APIRouter, File, UploadFile, HTTPException, BackgroundTasks, Request, Response, Depends
from fastapi.responses import JSONResponse
from pydantic import BaseModel
import numpy as np
from PIL import Image
import gc

from app.api.v1.deps.Auth import get_current_user
from app.utils.json_logger import json_logger  # âœ… ë³€ê²½: ncsa_logger â†’ json_logger

# Pillowì˜ decompression bomb ë³´í˜¸ í•´ì œ (ëŒ€ìš©ëŸ‰ ì´ë¯¸ì§€ ì²˜ë¦¬)
Image.MAX_IMAGE_PIXELS = None

router = APIRouter()

# ë””ë ‰í„°ë¦¬ ì„¤ì •
BASE_DIR = Path(__file__).resolve().parent.parent.parent.parent.parent
UPLOADS_BASE = os.environ.get("DATA_DIR", str(BASE_DIR / "uploads"))
CHUNK_SIZE = 512

# ê¸°ë³¸ uploads ë””ë ‰í„°ë¦¬ ìƒì„±
os.makedirs(UPLOADS_BASE, exist_ok=True)

print(f"[Neuroglancer] Uploads ê¸°ë³¸ ê²½ë¡œ: {UPLOADS_BASE}")


def get_user_data_root(username: str) -> str:
    """ì‚¬ìš©ìë³„ ë°ì´í„° ë£¨íŠ¸ ë””ë ‰í„°ë¦¬ ê²½ë¡œ ë°˜í™˜"""
    user_root = os.path.join(UPLOADS_BASE, username)
    os.makedirs(user_root, exist_ok=True)
    return user_root


def get_user_temp_dir(username: str) -> str:
    """ì‚¬ìš©ìë³„ ì„ì‹œ ë””ë ‰í„°ë¦¬ ê²½ë¡œ ë°˜í™˜"""
    temp_dir = os.path.join(UPLOADS_BASE, username, "temp")
    os.makedirs(temp_dir, exist_ok=True)
    return temp_dir


class VolumeInfo(BaseModel):
    """ë³¼ë¥¨ ì •ë³´ ëª¨ë¸"""
    name: str
    path: str
    info_url: str
    neuroglancer_url: str
    dimensions: Optional[List[int]] = None
    chunk_size: Optional[List[int]] = None


def validate_image_file(filename: str) -> bool:
    """íŒŒì¼ í™•ì¥ì ê²€ì¦"""
    return filename.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.tif', '.bmp'))


def process_chunk_from_image(
    img: Image.Image,
    chunk_x: int,
    chunk_y: int,
    chunk_size: int,
    volume_path: str,
    scale_key: str = "0",
) -> str:
    # 1) ì²­í¬ ì¢Œí‘œ ê³„ì‚°
    x_start = chunk_x * chunk_size
    y_start = chunk_y * chunk_size
    x_end = min(x_start + chunk_size, img.width)
    y_end = min(y_start + chunk_size, img.height)

    # 2) í•´ë‹¹ ì˜ì—­ë§Œ í¬ë¡­
    chunk_img = img.crop((x_start, y_start, x_end, y_end))

    # 3) numpy ë°°ì—´ë¡œ ë³€í™˜
    chunk_data = np.array(chunk_img, dtype=np.uint8)

    # 4) ì±„ë„ ì°¨ì› ì •ê·œí™” (H, W) -> (H, W, 1)
    if chunk_data.ndim == 2:
        chunk_data = chunk_data[:, :, np.newaxis]
    elif chunk_data.ndim != 3:
        raise ValueError(f"ì˜ˆìƒì¹˜ ëª»í•œ ì´ë¯¸ì§€ ì°¨ì›: {chunk_data.shape}")

    # í˜„ì¬: (H, W, C) = (Y, X, C)
    H, W, C = chunk_data.shape

    # 5) Neuroglancer raw: (C, Z, Y, X) ìˆœì„œë¡œ ì €ì¥
    # (H, W, C) -> (C, H, W)
    chunk_data = np.transpose(chunk_data, (2, 0, 1))
    # Z=1 ì¶• ì¶”ê°€ -> (C, 1, H, W)
    chunk_data = chunk_data[:, np.newaxis, :, :]

    # 6) íŒŒì¼ ì´ë¦„ ë° ê²½ë¡œ
    chunk_filename = f"{x_start}-{x_end}_{y_start}-{y_end}_0-1"
    scale_dir = os.path.join(volume_path, scale_key)
    os.makedirs(scale_dir, exist_ok=True)
    chunk_path = os.path.join(scale_dir, chunk_filename)

    # 7) Raw ë°”ì´ë„ˆë¦¬ ì €ì¥
    with open(chunk_path, "wb") as f:
        f.write(chunk_data.tobytes(order="C"))

    del chunk_data, chunk_img
    return chunk_path




def cleanup_temp_file(file_path: str):
    """ì„ì‹œ íŒŒì¼ ì •ë¦¬ (ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬)"""
    import time
    max_retries = 5

    for attempt in range(max_retries):
        try:
            if os.path.exists(file_path):
                os.remove(file_path)
                print(f"ì„ì‹œ íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {file_path}")
                return
            else:
                print(f"íŒŒì¼ì´ ì´ë¯¸ ì‚­ì œë¨: {file_path}")
                return
        except PermissionError:
            if attempt < max_retries - 1:
                print(f"íŒŒì¼ ì ê¸ˆ ê°ì§€, ì¬ì‹œë„ {attempt + 1}/{max_retries}")
                time.sleep(2 ** attempt)
            else:
                print(f"ì„ì‹œ íŒŒì¼ ì‚­ì œ ìµœì¢… ì‹¤íŒ¨: {file_path}")
        except Exception as e:
            print(f"ì„ì‹œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {file_path} - {str(e)}")
            return


@router.post("/upload")
async def upload_file(
        background_tasks: BackgroundTasks,
        request: Request,
        response: Response,
        file: UploadFile = File(...),
        current_user=Depends(get_current_user)
):
    """
    íŒŒì¼ ì—…ë¡œë“œ ë° Neuroglancer í˜•ì‹ìœ¼ë¡œ ìë™ ë³€í™˜

    - PNG, JPG, TIFF í˜•ì‹ ì§€ì›
    - ìë™ìœ¼ë¡œ precomputed í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    - ì²­í¬ ë‹¨ìœ„ë¡œ ì €ì¥í•˜ì—¬ ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬
    - ëŒ€ìš©ëŸ‰ TIFF íŒŒì¼ì„ ìœ„í•œ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
    """

    username = current_user.UserName
    print(f"[Upload] íŒŒì¼ ì—…ë¡œë“œ ìš”ì²­: {file.filename} by {username}")

    # íŒŒì¼ í˜•ì‹ ê²€ì¦
    if not validate_image_file(file.filename):
        await json_logger.log_request(
            request=request,
            response=response,
            auth_user=username,
            activity_type="UPLOAD_FAILED",
            details={"filename": file.filename, "reason": "invalid_format"}
        )
        raise HTTPException(
            status_code=400,
            detail="ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. PNG, JPG, TIFFë§Œ ì§€ì›í•©ë‹ˆë‹¤."
        )

    # ì‚¬ìš©ìë³„ ë””ë ‰í„°ë¦¬ ì„¤ì •
    user_data_root = get_user_data_root(username)
    user_temp_dir = get_user_temp_dir(username)

    print(f"[Upload] ì‚¬ìš©ì ë°ì´í„° ê²½ë¡œ: {user_data_root}")
    print(f"[Upload] ì„ì‹œ íŒŒì¼ ê²½ë¡œ: {user_temp_dir}")

    # ì„ì‹œ íŒŒì¼ ì €ì¥
    upload_path = os.path.join(user_temp_dir, file.filename)

    try:
        # íŒŒì¼ ì €ì¥
        content = await file.read()
        file_size = len(content)

        with open(upload_path, "wb") as buffer:
            buffer.write(content)
        print(f"[Upload] íŒŒì¼ ì €ì¥ ì™„ë£Œ: {file_size} bytes ({file_size / (1024 ** 3):.2f} GB)")

        # ë©”ëª¨ë¦¬ ì •ë¦¬
        del content
        gc.collect()

        # ë³¼ë¥¨ ì„¤ì • (ì‚¬ìš©ìë³„ ë””ë ‰í„°ë¦¬)
        volume_name = Path(file.filename).stem
        volume_path = os.path.join(user_data_root, volume_name)

        print(f"[Upload] ë³¼ë¥¨ ì´ë¦„: {volume_name}")
        print(f"[Upload] ë³¼ë¥¨ ê²½ë¡œ: {volume_path}")

        # Precomputed í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        print("[Upload] Precomputed í˜•ì‹ìœ¼ë¡œ ë³€í™˜ ì‹œì‘ (ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ)...")

        # ì´ë¯¸ì§€ ì—´ê¸° (ë©”ëª¨ë¦¬ì— ì „ì²´ë¥¼ ë¡œë“œí•˜ì§€ ì•ŠìŒ)
        img = Image.open(upload_path)
        width, height = img.size
        if img.mode == 'RGB':
            num_channels = 3
        elif img.mode == 'RGBA':
            num_channels = 4
        else: # L (Grayscale) ë“±
            num_channels = 1 
            
        print(f"[Upload] ì´ë¯¸ì§€ í¬ê¸°: {width}x{height}, ì±„ë„: {num_channels}")

        # ë³¼ë¥¨ ë””ë ‰í„°ë¦¬ ìƒì„±
        os.makedirs(volume_path, exist_ok=True)

        # ì²­í¬ ìˆ˜ ê³„ì‚°
        chunks_x = (width + CHUNK_SIZE - 1) // CHUNK_SIZE
        chunks_y = (height + CHUNK_SIZE - 1) // CHUNK_SIZE
        total_chunks = chunks_x * chunks_y

        print(f"[Upload] ì²­í¬ ìˆ˜: {chunks_x}x{chunks_y} = {total_chunks}ê°œ")
        print(f"[Upload] ì˜ˆìƒ ë©”ëª¨ë¦¬ ì‚¬ìš©: ì²­í¬ë‹¹ ~{(CHUNK_SIZE * CHUNK_SIZE) / (1024 ** 2):.2f} MB")

        # âœ… ì²­í¬ ë°ì´í„° ì €ì¥ (ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ - ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
        print("[Upload] ì²­í¬ ë°ì´í„° ì €ì¥ ì‹œì‘ (ìŠ¤íŠ¸ë¦¬ë°)...")
        saved_chunks = 0

        for cy in range(chunks_y):
            for cx in range(chunks_x):
                chunk_path = process_chunk_from_image(
                    img, cx, cy, CHUNK_SIZE, volume_path, scale_key="0"
                )
                saved_chunks += 1

                # ì§„í–‰ ìƒí™© ë¡œê·¸ (100ê°œë§ˆë‹¤ ë˜ëŠ” ë§ˆì§€ë§‰)
                if saved_chunks % 100 == 0 or saved_chunks == total_chunks:
                    progress = (saved_chunks / total_chunks) * 100
                    print(f"[Upload] ì²­í¬ ì €ì¥ ì§„í–‰: {saved_chunks}/{total_chunks} ({progress:.1f}%)")

                # ì£¼ê¸°ì ìœ¼ë¡œ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ (ë©”ëª¨ë¦¬ ì •ë¦¬)
                if saved_chunks % 500 == 0:
                    gc.collect()

        # ì´ë¯¸ì§€ ë‹«ê¸°
        img.close()
        del img
        gc.collect()

        print(f"[Upload] ì´ {saved_chunks}ê°œ ì²­í¬ ì €ì¥ ì™„ë£Œ!")

        # info íŒŒì¼ ìƒì„±
        info = {
            "@type": "neuroglancer_multiscale_volume",
            "type": "image",
            "data_type": "uint8",
            "num_channels": num_channels, # ğŸ‘ˆ ë™ì ìœ¼ë¡œ ì„¤ì •ëœ num_channels ì‚¬ìš©
            "scales": [
                {
                    "key": "0",
                    "size": [width, height, 1],
                    "resolution": [1, 1, 1],
                    "voxel_offset": [0, 0, 0],
                    # ì²­í¬ í¬ê¸°ë„ num_channelsì— ë§ê²Œ ì¡°ì • (Zì¶• 1ë¡œ ê³ ì • ìœ ì§€)
                    "chunk_sizes": [[CHUNK_SIZE, CHUNK_SIZE, 1]], 
                    "encoding": "raw"
                }
            ]
        }

        info_path = os.path.join(volume_path, "info")
        with open(info_path, 'w') as f:
            json.dump(info, f, indent=2)

        print("[Upload] info íŒŒì¼ ì €ì¥ ì™„ë£Œ")
        print("[Upload] ë°ì´í„° ì €ì¥ ì™„ë£Œ")

        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì„ì‹œ íŒŒì¼ ì •ë¦¬
        background_tasks.add_task(cleanup_temp_file, upload_path)

        # ì—…ë¡œë“œ ì„±ê³µ ë¡œê¹…
        await json_logger.log_request(
            request=request,
            response=response,
            auth_user=username,
            activity_type="VOLUME_UPLOAD",
            details={
                "volume_name": volume_name,
                "file_size": file_size,
                "dimensions": f"{width}x{height}",
                "chunks": total_chunks
            }
        )

        # ì‚¬ìš©ì í™œë™ ë¡œê¹…
        json_logger.log_activity(
            username=username,
            activity="IMAGE_UPLOADED",
            status="SUCCESS",
            details={
                "filename": file.filename,
                "volume": volume_name,
                "size_bytes": file_size,
                "width": width,
                "height": height,
                "chunks": total_chunks
            }
        )

        # ì²­í¬ ë¶„ë¦¬ í™œë™ ë¡œê¹…
        json_logger.log_activity(
            username=username,
            activity="CHUNK_SPLIT",
            status="SUCCESS",
            details={
                "volume": volume_name,
                "chunk_size": CHUNK_SIZE,
                "total_chunks": total_chunks,
                "chunks_x": chunks_x,
                "chunks_y": chunks_y,
                "saved_chunks": saved_chunks
            }
        )

        return JSONResponse(content={
            "message": "íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ê³  ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "volume_name": volume_name,
            "username": username,
            "volume_path": f"/uploads/{username}/{volume_name}",
            "neuroglancer_url": f"precomputed://http://localhost:8000/uploads/{username}/{volume_name}",
            "dimensions": [width, height, 1],
            "num_channels": num_channels,
            "chunk_size": CHUNK_SIZE,
            "total_chunks": total_chunks,
            "saved_chunks": saved_chunks
        })

    except Exception as e:
        # ì—ëŸ¬ ë°œìƒ ì‹œ ì„ì‹œ íŒŒì¼ ì •ë¦¬
        if os.path.exists(upload_path):
            background_tasks.add_task(cleanup_temp_file, upload_path)

        print(f"[Upload ERROR] {str(e)}")
        import traceback
        traceback.print_exc()

        # ë©”ëª¨ë¦¬ ì •ë¦¬
        gc.collect()

        # ì—…ë¡œë“œ ì‹¤íŒ¨ ë¡œê¹…
        await json_logger.log_request(
            request=request,
            response=response,
            auth_user=username,
            activity_type="UPLOAD_ERROR",
            details={
                "filename": file.filename,
                "error": str(e)
            }
        )

        json_logger.log_activity(
            username=username,
            activity="IMAGE_UPLOAD_FAILED",
            status="FAILED",
            details={
                "filename": file.filename,
                "error": str(e)
            }
        )

        return JSONResponse(
            status_code=500,
            content={
                "error": "upload_failed",
                "message": f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "detail": str(e)
            }
        )


@router.get("/volumes")
async def list_volumes(
        request: Request,
        response: Response,
        current_user=Depends(get_current_user)
):
    """
    ì‚¬ìš© ê°€ëŠ¥í•œ ë³¼ë¥¨ ëª©ë¡ ë°˜í™˜

    - ë³€í™˜ëœ ëª¨ë“  ë³¼ë¥¨ì˜ ëª©ë¡ê³¼ ìƒì„¸ ì •ë³´ ì œê³µ
    - í˜„ì¬ ì‚¬ìš©ìì˜ ë³¼ë¥¨ë§Œ í‘œì‹œ
    """
    try:
        username = current_user.UserName
        user_data_root = get_user_data_root(username)

        volumes = []
        if os.path.exists(user_data_root):
            for item in os.listdir(user_data_root):
                # temp ë””ë ‰í„°ë¦¬ ì œì™¸
                if item == "temp" or item.startswith("temp_"):
                    continue

                volume_path = os.path.join(user_data_root, item)
                if os.path.isdir(volume_path):
                    info_path = os.path.join(volume_path, "info")
                    if os.path.exists(info_path):
                        # info íŒŒì¼ì—ì„œ ìƒì„¸ ì •ë³´ ì½ê¸°
                        with open(info_path, 'r') as f:
                            info = json.load(f)

                        volumes.append({
                            "name": item,
                            "username": username,
                            "path": f"/uploads/{username}/{item}",
                            "info_url": f"/uploads/{username}/{item}/info",
                            "neuroglancer_url": f"precomputed://http://localhost:8000/uploads/{username}/{item}",
                            "dimensions": info['scales'][0]['size'] if 'scales' in info else None,
                            "chunk_size": info['scales'][0]['chunk_sizes'][0] if 'scales' in info else None
                        })

        # ë³¼ë¥¨ ëª©ë¡ ì¡°íšŒ ë¡œê¹…
        await json_logger.log_request(
            request=request,
            response=response,
            auth_user=username,
            activity_type="LIST_VOLUMES",
            details={"volume_count": len(volumes)}
        )

        return JSONResponse(content={"volumes": volumes, "count": len(volumes)})

    except Exception as e:
        await json_logger.log_request(
            request=request,
            response=response,
            auth_user=current_user.UserName,
            activity_type="LIST_VOLUMES_ERROR",
            details={"error": str(e)}
        )
        raise HTTPException(
            status_code=500,
            detail=f"ë³¼ë¥¨ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"
        )


@router.get("/volumes/{volume_name}/info")
async def get_volume_info(
        volume_name: str,
        request: Request,
        response: Response,
        current_user=Depends(get_current_user)
):
    """
    íŠ¹ì • ë³¼ë¥¨ì˜ ìƒì„¸ ì •ë³´ ë°˜í™˜

    - info íŒŒì¼ ë‚´ìš©ê³¼ ë©”íƒ€ë°ì´í„° ì œê³µ
    - í˜„ì¬ ì‚¬ìš©ìì˜ ë³¼ë¥¨ë§Œ ì ‘ê·¼ ê°€ëŠ¥
    """
    try:
        username = current_user.UserName
        user_data_root = get_user_data_root(username)
        volume_path = os.path.join(user_data_root, volume_name)
        info_path = os.path.join(volume_path, "info")

        if not os.path.exists(info_path):
            await json_logger.log_request(
                request=request,
                response=response,
                auth_user=username,
                activity_type="VOLUME_NOT_FOUND",
                details={"volume_name": volume_name}
            )
            raise HTTPException(
                status_code=404,
                detail="ë³¼ë¥¨ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            )

        with open(info_path, "r", encoding="utf-8") as f:
            info = json.load(f)

        # ë³¼ë¥¨ ì •ë³´ ì¡°íšŒ ë¡œê¹…
        await json_logger.log_request(
            request=request,
            response=response,
            auth_user=username,
            activity_type="VIEW_VOLUME_INFO",
            details={"volume_name": volume_name}
        )

        # ì´ë¯¸ì§€ ì—´ê¸° í™œë™ ë¡œê¹…
        json_logger.log_activity(
            username=username,
            activity="IMAGE_VIEW",
            status="SUCCESS",
            details={
                "volume": volume_name,
                "dimensions": info['scales'][0]['size'] if 'scales' in info else None
            }
        )

        return JSONResponse(content={
            "volume_name": volume_name,
            "username": username,
            "info": info,
            "volume_path": f"/uploads/{username}/{volume_name}",
            "neuroglancer_url": f"precomputed://http://localhost:8000/uploads/{username}/{volume_name}"
        })

    except HTTPException:
        raise
    except Exception as e:
        await json_logger.log_request(
            request=request,
            response=response,
            auth_user=current_user.UserName,
            activity_type="VIEW_VOLUME_ERROR",
            details={"volume_name": volume_name, "error": str(e)}
        )
        raise HTTPException(
            status_code=500,
            detail=f"ë³¼ë¥¨ ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )


@router.delete("/volumes/{volume_name}")
async def delete_volume(
        volume_name: str,
        background_tasks: BackgroundTasks,
        request: Request,
        response: Response,
        current_user=Depends(get_current_user)
):
    """
    ë³¼ë¥¨ ì‚­ì œ

    - ì§€ì •ëœ ë³¼ë¥¨ê³¼ ê´€ë ¨ ë°ì´í„°ë¥¼ ëª¨ë‘ ì‚­ì œ
    - í˜„ì¬ ì‚¬ìš©ìì˜ ë³¼ë¥¨ë§Œ ì‚­ì œ ê°€ëŠ¥
    """
    try:
        username = current_user.UserName
        user_data_root = get_user_data_root(username)
        volume_path = os.path.join(user_data_root, volume_name)

        if not os.path.exists(volume_path):
            await json_logger.log_request(
                request=request,
                response=response,
                auth_user=username,
                activity_type="DELETE_VOLUME_FAILED",
                details={"volume_name": volume_name, "reason": "not_found"}
            )
            raise HTTPException(
                status_code=404,
                detail="ë³¼ë¥¨ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            )

        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‚­ì œ
        background_tasks.add_task(shutil.rmtree, volume_path)

        # ë³¼ë¥¨ ì‚­ì œ ë¡œê¹…
        await json_logger.log_request(
            request=request,
            response=response,
            auth_user=username,
            activity_type="VOLUME_DELETE",
            details={"volume_name": volume_name}
        )

        json_logger.log_activity(
            username=username,
            activity="VOLUME_DELETED",
            status="SUCCESS",
            details={"volume": volume_name}
        )

        return JSONResponse(content={
            "message": f"ë³¼ë¥¨ '{volume_name}'ì´ ì‚­ì œ ëŒ€ê¸°ì—´ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤."
        })

    except HTTPException:
        raise
    except Exception as e:
        await json_logger.log_request(
            request=request,
            response=response,
            auth_user=current_user.UserName,
            activity_type="DELETE_VOLUME_ERROR",
            details={"volume_name": volume_name, "error": str(e)}
        )
        raise HTTPException(
            status_code=500,
            detail=f"ë³¼ë¥¨ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )


@router.get("/test-upload")
async def test_upload_setup(
        request: Request,
        response: Response,
        current_user=Depends(get_current_user)
):
    """
    ì—…ë¡œë“œ ì„¤ì • í…ŒìŠ¤íŠ¸

    - ë””ë ‰í„°ë¦¬ ìƒíƒœ ë° ì„¤ì • í™•ì¸ìš©
    """
    username = current_user.UserName
    user_data_root = get_user_data_root(username)
    user_temp_dir = get_user_temp_dir(username)

    # í…ŒìŠ¤íŠ¸ ìš”ì²­ ë¡œê¹…
    await json_logger.log_request(
        request=request,
        response=response,
        auth_user=username,
        activity_type="TEST_UPLOAD_CONFIG",
        details={"action": "check_setup"}
    )

    return JSONResponse(content={
        "username": username,
        "uploads_base": UPLOADS_BASE,
        "user_data_root": user_data_root,
        "user_temp_dir": user_temp_dir,
        "uploads_base_exists": os.path.exists(UPLOADS_BASE),
        "user_data_root_exists": os.path.exists(user_data_root),
        "user_temp_dir_exists": os.path.exists(user_temp_dir),
        "chunk_size": CHUNK_SIZE
    })